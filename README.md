# ðŸ›°ï¸ Dual-Image Super-Resolution using EDSR (with Concatenation Fusion)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12%2B-red?logo=pytorch)](https://pytorch.org/)
A deep learning-based Dual-Image Super-Resolution framework built using a modified **EDSR (Enhanced Deep Super-Resolution)** architecture. The model takes **two temporally shifted low-resolution satellite images** and fuses them to generate a high-resolution output. Fusion is achieved via **simple channel-wise concatenation** followed by deep residual refinement.

---

## ðŸ“– Overview

This project targets the problem of enhancing the spatial resolution of satellite images captured at different times. Since high-res satellites are costly and limited, we leverage **multiple low-resolution inputs** captured over time to reconstruct the corresponding high-resolution image.

This approach is especially useful for missions like **Proba-V**, where the trade-off between spatial and temporal resolution limits imagery quality.

---

## ðŸ“ Articles & Documentation

Iâ€™ve written a series of Medium blogs that explain this project step-by-step â€” from dataset preparation to building the model, training it, and visualizing results.

You can read the full journey here:

* ðŸ“„ [Part 1: Dataset Creation & Preprocessing](https://medium.com/@Phineouse/dual-image-super-resolution-for-high-resolution-optical-satellite-imagery-data-preprocessing-605fe123152e)
  *Covers how the Proba-V satellite dataset was normalized, filtered, and restructured for dual-image SR training.*

* ðŸ§  [Part 2: Building the Model Architecture (EDSR + Fusion)](https://medium.com/@Phineouse/dual-image-super-resolution-for-high-resolution-optical-satellite-imagery-data-preprocessing-605fe123152e)
  *Explains the PyTorch model architecture including the use of EDSR blocks, concatenation fusion, and PixelShuffle.*

* ðŸ“Š [Part 3: Training, Evaluation (PSNR), and Inference](https://medium.com/@Phineouse/dual-image-super-resolution-for-high-resolution-optical-satellite-imagery-data-loader-class-and-f256e2679114)
  *Discusses training strategy, metrics, loss functions, and how to visualize and interpret the results.*
  
  ðŸ“– All concepts are explained clearly with examples, visuals, and reasoning, so donâ€™t worry if youâ€™re new to this!

> These articles are written in a beginner-friendly tone with technical clarity, so even if youâ€™re just getting started with deep learning or super-resolution, youâ€™ll find them easy to follow.

> If you find the articles helpful, feel free to give them a follow or clap on Medium â€” it helps spread the word and supports open-source learning!


---

Let me know if you'd like to add image previews or article badges!


## ðŸ—‚ï¸ Dataset
* [Main dataset PROBAV](https://drive.google.com/file/d/1BAGjd5ScCXNF2Y6ffBUopUnctqVhLq8J/view)
* [Preprocessed and final dualsr dataset ](https://kelvins.esa.int/proba-v-super-resolution/data/)

This project uses a preprocessed version of the **Proba-V Super-Resolution Dataset**. The structure is as follows:

```

dual\_sr\_dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ low\_res/
â”‚   â”‚   â”œâ”€â”€ imgsetXXXX\_LR0.png
â”‚   â”‚   â”œâ”€â”€ imgsetXXXX\_LR1.png
â”‚   â””â”€â”€ high\_res/
â”‚       â”œâ”€â”€ imgsetXXXX\_HR.png
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ low\_res/
â”‚   â””â”€â”€ high\_res/

```

Each sample consists of:
- `LR0`: Low-res image at time t
- `LR1`: Low-res image at time t+1
- `HR`: Ground truth high-res image

---

## ðŸ§  Model Architecture

The model combines dual inputs using **channel-wise concatenation** after feature extraction and processes the merged tensor through an **EDSR-style backbone** for refinement.

```

LR1        LR2
â”‚          â”‚
\[Conv]    \[Conv]
â”‚          â”‚
â””â”€> \[Concat + Fusion Block] â”€â”€> \[EDSR Backbone] â”€â”€> \[Upsample] â”€â”€> SR Output

````

### Components:
- `InitialConvBlock`: 3Ã—3 conv + ReLU per LR input
- `FusionBlock`: 1Ã—1 conv to reduce channel size
- `EDSRBackbone`: Stack of Residual Blocks (default: 8)
- `UpsampleBlock`: Conv â†’ PixelShuffle to upscale

---

## âš™ï¸ Training Details

- **Framework**: PyTorch  
- **Input Size**: LR = 64Ã—64, HR = 256Ã—256  
- **Scaling Factor**: Ã—4  
- **Loss Function**: L1 / Combined Loss (L1 + PSNR)  
- **Optimizer**: Adam  
- **Learning Rate**: 1e-4  
- **Epochs**: 50  
- **Batch Size**: 4  

Model checkpoints are saved in the `checkpoints/` directory.

---

## ðŸ“Š Evaluation Metrics

The performance is evaluated using:

- **PSNR (Peak Signal-to-Noise Ratio)**

Higher values indicate better reconstruction.

---

## âœ… Results

Example: Dual inputs, model output, and ground truth comparison.
## ðŸ” Sample Output

Hereâ€™s an example of how the model enhances resolution:

![Sample Output](https://github.com/vnayakde/Dual-Image-Super-Resolution-for-High-Resolution-Optical-Satellite-Imagery/blob/main/e03bab5c-a2ba-47a4-bf61-3b6a421a929b.jpeg)


> Sample outputs and intermediate visualizations are stored in the `sr_visualization/` directory.

---

## ðŸ“š References

* [EDSR Paper (CVPR 2017)](https://arxiv.org/abs/1707.02921)
* [Proba-V Dataset](https://kelvins.esa.int/proba-v-super-resolution/)
* [PixelShuffle Docs](https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html)

---


